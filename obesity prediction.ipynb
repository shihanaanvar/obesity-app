# ---------------------------------------------------------
# ðŸ“Œ 1. IMPORT LIBRARIES
# ---------------------------------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, confusion_matrix, classification_report
)

import joblib


# ---------------------------------------------------------
# ðŸ“Œ 2. LOAD DATASET
# ---------------------------------------------------------
df = pd.read_csv("ObesityDataSet_raw_and_data_sinthetic.csv")
print("Dataset Loaded!")
print(df.head())


# ---------------------------------------------------------
# ðŸ“Œ 3. FIX COLUMN RENAMING (YOURS HAD DUPLICATES)
# ---------------------------------------------------------
rename_columns = {
    "FCVC": "Vegetable_Consumption_Frequency",
    "FAVC": "Frequent_HighCalorie_Food_Consumption",
    "NCP": "Number_of_Main_Meals",
    "CAEC": "Food_Between_Meals",
    "CH2O": "Daily_Water_Intake_Liters",
    "FAF": "Physical_Activity_Frequency",
    "TUE": "Time_Using_Electronic_Devices",
    "MTRANS": "Mode_of_Transportation"
}

df = df.rename(columns=rename_columns)
df.to_csv("renamed_obesity_dataset.csv", index=False)
print("Columns Renamed Successfully!")


# ---------------------------------------------------------
# ðŸ“Œ 4. CLEAN HEIGHT + WEIGHT + COMPUTE BMI
# ---------------------------------------------------------
height_col = [col for col in df.columns if "height" in col.lower()][0]
weight_col = [col for col in df.columns if "weight" in col.lower()][0]

df[height_col] = pd.to_numeric(df[height_col], errors="coerce")
df[weight_col] = pd.to_numeric(df[weight_col], errors="coerce")

# Convert cm â†’ meters
if df[height_col].mean() > 3:
    df[height_col] = df[height_col] / 100

df["BMI"] = df[weight_col] / (df[height_col] ** 2)

print("BMI Added!")


# ---------------------------------------------------------
# ðŸ“Œ 5. DEFINE OBESITY CLASS FUNCTION
# ---------------------------------------------------------
def bmi_to_class(b):
    if b < 18.5:
        return "Underweight"
    elif b < 25:
        return "Normal"
    elif b < 30:
        return "Overweight"
    elif b < 35:
        return "Obesity I"
    elif b < 40:
        return "Obesity II"
    else:
        return "Obesity III"

df["obesity_level"] = df["BMI"].apply(bmi_to_class)


# ---------------------------------------------------------
# ðŸ“Œ 6. FEATURE SELECTION
# ---------------------------------------------------------
X = df.drop(columns=["obesity_level"])
y = df["obesity_level"]

print("X shape:", X.shape)
print("y shape:", y.shape)


# ---------------------------------------------------------
# ðŸ“Œ 7. TRAIN-TEST SPLIT
# ---------------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)


# ---------------------------------------------------------
# ðŸ“Œ 8. ONE-HOT ENCODING + ALIGN COLUMNS
# ---------------------------------------------------------
X_train_enc = pd.get_dummies(X_train, drop_first=True)
X_test_enc = pd.get_dummies(X_test, drop_first=True)

X_train_enc, X_test_enc = X_train_enc.align(X_test_enc, join="left", axis=1, fill_value=0)

print("Encoding Completed!")


# ---------------------------------------------------------
# ðŸ“Œ 9. TRAIN INITIAL MODEL
# ---------------------------------------------------------
model = RandomForestClassifier(n_estimators=200, random_state=42)
model.fit(X_train_enc, y_train)

print("Initial RandomForest model trained successfully!")


# ---------------------------------------------------------
# ðŸ“Œ 10. GRIDSEARCH MODEL TUNING
# ---------------------------------------------------------
param_grid = {
    "n_estimators": [100, 200, 300],
    "max_depth": [None, 10, 20],
    "min_samples_split": [2, 5],
    "min_samples_leaf": [1, 2],
    "bootstrap": [True, False]
}

rf = RandomForestClassifier(random_state=42)

grid_search = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    cv=3,
    scoring="f1_macro",
    n_jobs=-1,
    verbose=1
)

print("Running GridSearchCV...")
grid_search.fit(X_train_enc, y_train)

best_model = grid_search.best_estimator_
print("Best Model Found!")


# ---------------------------------------------------------
# ðŸ“Œ 11. MODEL EVALUATION
# ---------------------------------------------------------
y_pred = best_model.predict(X_test_enc)

print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average="macro"))
print("Recall:", recall_score(y_test, y_pred, average="macro"))
print("F1 Score:", f1_score(y_test, y_pred, average="macro"))

print("\nClassification Report:\n", classification_report(y_test, y_pred))


# ---------------------------------------------------------
# ðŸ“Œ 12. CONFUSION MATRIX VISUALIZATION
# ---------------------------------------------------------
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens")
plt.title("Obesity Level Confusion Matrix")
plt.show()


# ---------------------------------------------------------
# ðŸ“Œ 13. SAVE MODEL + ENCODER COLUMNS FOR STREAMLIT
# ---------------------------------------------------------
joblib.dump(best_model, "obesity_model.pkl")
joblib.dump(X_train_enc.columns, "model_columns.pkl")

print("Saved obesity_model.pkl & model_columns.pkl successfully!")
